# **模型评价指标**
## 1 综述
### 1.1 评价指标引入相关概念：
### 1.1.1 引入概念
- 训练集
- 测试集
- 网格搜索
- 交叉验证

### 1.1.2 离散型衡量指标
- 分类准确度（accuracy）
- 混淆矩阵（第一位表示预测准确性，第二位表示预测值）
    方法名 | 预测值P(positive) | 预测值N(negative)
    :--:|:--:|:--:
    真实值T(true) | TP | FN
    真实值F(false)	| FP | TN
- 精确率（查准率）：（所有预测为真的样本中，正确预测所占比例。即我们关注的那个事件，预测的有多准。）
   - 应用场景：股票，买升的，即使漏了也没关系。 

\frac{TP}{TP+FP}
 
- 召回率（查全率）：（所有真样本中，预测为真的占比。我们关注的那个事件真实的发生情况下，我们成功预测的比例是多少。）
    - 应用场景：把所有有病的都查出来。

\frac{TP}{TP+FN}

- F1 Score

F1 = \frac{2*precision*recall}{precision+recall}

- TPR(所有真样本中，预测成功的占比，即为召回率。)
- FPR(所有假样本中，预测失败的占比)

\frac{FP}{FP+TN}

- ROC曲线
    - 一条用来衡量分类器分类效果的曲线，曲线越靠左上角，说明，无论阀值怎么取，对分类器影响越小，可以通过画图直观地看出分类器的效果。
- AUC曲线
    - 对ROC曲线求积分，主要用于直观衡量不同分类器的分类效果。
    - AUC=1：是完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。
    - 0.5 < AUC < 1：优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。
    - AUC = 0.5，跟随机猜测一样，模型没有预测价值。
    - AUC < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。
  

### 1.1.3 连续型衡量指标
- 均方误差MSE

MSE = \frac{1}{m}\sum_{i=1}^{m}\frac{1}{x^2}(y_{text}^{(i)}, \hat{y}<sub>text</sub>^{(i)})^2

- 均方根误差RMSE

RMSE = \sqrt{(\frac{1}{m}\sum_{i=1}^{m}\frac{1}{x^2}(y_{text}^{(i)}, \hat{y} _{text}^{(i)})}=\sqrt{MSE_{test}}

- 平均绝对误差MAE

MAE = \frac{1}{m}\sum_{i=1}^{m}\frac{1}{x^2}|y_{text}^{(i)}, \hat{y}<sub>text</sub>^{(i)}|\\


- SSR:（回归平方和：预测数据与原始数据均值之差的平方和）

SSR = \sum_{i=1}^{n}(\hat{y}_{i}- \bar{y}_{i})^2\\

- SST:（总离差平方和：原始数据与原始数据均值之差的平方和）

SST = \sum_{i=1}^{n}({y}_{i}- \bar{y}_{i})^2\\

- SSE:（残差平方和：拟合数据和原始数据对应点的误差的平方和）

SSE = \sum_{i=1}^{n}({y}_{i}- \hat{y}_{i})^2\\

- R Square
    - 产生背景：由于MSE并没处于在(0,1)之间，不能对比不同事物的情况。于是，产生R方用于比较模型与basemodel的优异。
    - 通俗解释：通过以原始均值为标杆，分别求原始值和预测值离这个标杆有多远。做一个比值，就是R方。
    - 解释：
        - 对于分子来说，预测值和真实值之差的平方和，即使用我们的模型预测产生的错误。
        - 对于分母来说，是均值和真实值之差的平方和，即baselinemodel的离散情况。
    - 结论：
        - R方越大越好，当R方为1时，模型预测准确率为100%。
        - R方为0时，模型为基模型。
        - R方小于0时，我们的模型不如基模型，数据不存在任何线性关系

R-square = \frac{SSR}{SST} = \frac{SST - SSE}{SST} = 1 - \frac{SSE}{SST}=1-\frac{MSE(\hat{y}^{(i)},y)}{Var(y)}

### 2 代码实现

文件名 | 描述 
:-:|:-:
01_train_test_split_code.py|数据集划分手写代码
02_train_test_split_toclass.py|数据集划分代码封装
03_handwrite.py|k近邻手写数字模型，网格搜索调参数
04_confusion_matrix.py|逻辑回归，手写计算混淆矩阵代码
05_ROC.py|TRP和FPR的求解代码和ROC的绘制和AOC的求解。
06_liner_model.py|连续型模型中的模型评价方法。
07_model_in_sklearn.py|数据集划分、ROC、AUR、召回率在sklearn中的调用。
Metrics.py|计算准确率的封装方法。

